{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d1a1482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Imports\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "import time \n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6730d761",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e920665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://techcommunity.microsoft.com/t5/educator-developer-blog/how-to-scrape-twitter-data-for-sentiment-analysis-with-python/ba-p/3593365\n",
    "\n",
    "def scrape_tweets(topic, start_date, end_date):\n",
    "    '''\n",
    "    Returns the set of English language tweets containing a specific hashtag between a date range\n",
    "    \n",
    "    Parameters: \n",
    "        topic (str): string describing hashtag (e.g. \"#Oscars2022\")\n",
    "        start_date (str): string for start of date range (e.g. YYYY-MM-DD)\n",
    "        end_date (str): string for start of date range (e.g. YYYY-MM-DD)\n",
    "    \n",
    "    Returns: \n",
    "        df (DataFrame): DataFrame containing date of tweet and tweet contents\n",
    "    '''\n",
    "    \n",
    "    # Max number of tweets to pull\n",
    "    NUM_TWEETS = 1000000\n",
    "\n",
    "    # Filtering to English language tweets between start and end date\n",
    "    query = \"({}) since:{} until:{} lang:en\".format(topic, start_date, end_date)\n",
    "\n",
    "    tweets = []\n",
    "    data = enumerate(sntwitter.TwitterSearchScraper(query).get_items())\n",
    "    for i, tweet in data: \n",
    "        if i>NUM_TWEETS: \n",
    "            break\n",
    "        else: \n",
    "            tweets.append([tweet.date, tweet.content])\n",
    "\n",
    "    df = pd.DataFrame(tweets, columns = ['Date', 'tweet'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dcc7751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_related_hashtags(data, num_topics): \n",
    "    '''\n",
    "    Finds the most commonly occuring hashtags in a tweet\n",
    "    \n",
    "    Parameters: \n",
    "        data (DataFrame): DataFrame containing tweets \n",
    "        num_topics (int): The number of most related hashtags to return \n",
    "    \n",
    "    Returns: \n",
    "        hashtags_counter (list): List of tuples containing the most commonly occuring hashtags \n",
    "        and the number of times that they occur\n",
    "    '''\n",
    "    \n",
    "    related_hashtags = []\n",
    "\n",
    "    for tweet in data['tweet']: \n",
    "        tweet = tweet.lower()\n",
    "        hashtags = re.findall(r'\\B#\\w*[a-zA-Z]+\\w*', tweet)\n",
    "        related_hashtags.extend(hashtags)\n",
    "        \n",
    "    hashtags_counter = Counter(related_hashtags).most_common(num_topics+1)\n",
    "    return hashtags_counter[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8018e1b2",
   "metadata": {},
   "source": [
    "# Scraping Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3ad70d",
   "metadata": {},
   "source": [
    "## #Oscars2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd6139d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping tweets for overarching #Oscars2022 hashtag \n",
    "\n",
    "st = time.time()\n",
    "df = scrape_tweets(\"#Oscars2022\", \"2022-03-27\", \"2022-03-28\")\n",
    "et = time.time()\n",
    "print(et - st)\n",
    "\n",
    "oscars_pkl = df.to_pickle(\"./oscars.pkl\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dbed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding 20 most mentioned hashtags in #Oscars2022 tweets\n",
    "oscars_top_20 = find_related_hashtags(oscars_df, 20)\n",
    "\n",
    "# Subsetting to the most interesting 15 \n",
    "top_15_oscars = [\"#academyawards\", \"#redcarpet\", \"#dune\", \"#oscarsfanfavorite\", \"#coda\", \"#thepowerofthedog\", \"#bestpicture\", \"#westsidestory\", \n",
    "\"#andrewgarfield\", \"#zendaya\", \"#hollywood\", \"#movies\", \"#kristenstewart\", \"#oscarnoms\", \"#oscars\"]\n",
    "\n",
    "# Scraping all tweets for each of the 15 sub-topics\n",
    "for i in top_15_oscars: \n",
    "    print(i)\n",
    "    df = scrape_tweets(i, \"2022-03-27\", \"2022-03-28\")\n",
    "    pkl = df.to_pickle(i[1:]+\".pkl\") \n",
    "\n",
    "    \n",
    "# Find two most common hashtags for 15 sub-topics\n",
    "oscars_topic_dict = {}\n",
    "st = time.time()\n",
    "\n",
    "for topic in top_15_oscars: \n",
    "    data = pd.read_pickle(topic[1:] + \".pkl\")\n",
    "    hashtags = find_related_hashtags(data, 2)\n",
    "    oscars_topic_dict[topic] = [i[0] for i in hashtags]   \n",
    "\n",
    "et = time.time()\n",
    "print(et - st)\n",
    "\n",
    "# Save subtopics to json\n",
    "json.dump(oscars_topic_dict, open(\"oscars_subtopics.json\", 'w' ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bf663a",
   "metadata": {},
   "source": [
    "## #UKPolitics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea71026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping tweets for overarching #UKPolitics hashtag\n",
    "st = time.time()\n",
    "uk_df = scrape_tweets(\"#UKPolitics\", \"2022-07-05\", \"2022-10-26\")\n",
    "et = time.time()\n",
    "print(et - st)\n",
    "\n",
    "uk_pkl = uk_df.to_pickle(\"./uk.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acc962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding 20 most mentioned hashtags in #UKPolitics tweets\n",
    "uk_top_20 = find_related_hashtags(uk_df, 20)\n",
    "\n",
    "# Subselecting to the 15 most interesting\n",
    "top_15_uk = [\"#liztruss\", \"#borisjohnson\", \"#uk\", \"#rishisunak\", \"#brexit\", \"#toryshambles\", \"#politics\", \"#gtto\", \"#murdochguttermedia\",\n",
    "            \"#progressivealliance\", \"#dissolvetheunion\", \"#dailyfail\", \"#nastyparty\", \"#rwnjs\", \"#torybritain\"]\n",
    "\n",
    "# Scraping all tweets for each of the 15 sub-topics\n",
    "for i in top_15_uk: \n",
    "    print(i)\n",
    "    df = scrape_tweets(i, \"2022-07-05\", \"2022-10-26\")\n",
    "    pkl = df.to_pickle(i[1:]+\".pkl\") \n",
    "    \n",
    "\n",
    "uk_topic_dict = {}\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "# Find two most common hashtags for 15 sub-topics\n",
    "for topic in top_15_uk: \n",
    "    data = pd.read_pickle(topic[1:] + \".pkl\")\n",
    "    hashtags = find_related_hashtags(data, 2)\n",
    "    uk_topic_dict[topic] = [i[0] for i in hashtags]   \n",
    "\n",
    "et = time.time()\n",
    "print(et - st)\n",
    "\n",
    "# Save subtopics to json\n",
    "json.dump(uk_topic_dict, open(\"uk_subtopics.json\", 'w' ) )\n",
    "\n",
    "\n",
    "# Scrape tweets for additional hashtags (2 most common)\n",
    "extra_topics = ['#london', '#eu', '#generalelectionnow', '#torychaos', '#news' , '#followbackfriday', '#murdochroyalcommission', '#auspol', \n",
    "                '#scottishindependence2023', '#indyref2', '#musicvideo', '#newmusic']\n",
    "\n",
    "for i in extra_topics: \n",
    "    print(i)\n",
    "    df = scrape_tweets(i, \"2022-09-26\", \"2022-10-26\")\n",
    "    pkl = df.to_pickle(i[1:]+\".pkl\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
